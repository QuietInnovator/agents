{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach the ethical dilemmas presented by the deployment of artificial intelligence in decision-making processes that affect marginalized communities, and what specific frameworks would you utilize to ensure fairness and accountability?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Redesigning a major urban area to be more sustainable while ensuring social equity requires a comprehensive and collaborative approach. Below are specific policies and innovations I would implement, along with strategies for addressing potential opposition from different community stakeholders.\n",
       "\n",
       "### Policies and Innovations\n",
       "\n",
       "1. **Mixed-Income Housing Developments**:\n",
       "   - **Policy**: Implement zoning reforms that encourage mixed-income housing to ensure affordability and diversity.\n",
       "   - **Innovation**: Promote community land trusts and cooperative housing models to empower residents and retain affordability.\n",
       "\n",
       "2. **Community-Centric Transportation Networks**:\n",
       "   - **Policy**: Expand public transportation options, including electric buses, light rail, and bike-share programs, with free or low-cost fares for low-income residents.\n",
       "   - **Innovation**: Invest in smart transportation technologies (e.g., apps for multi-modal transport options) that facilitate easy navigation across various transport means.\n",
       "\n",
       "3. **Green Infrastructure**:\n",
       "   - **Policy**: Mandate the integration of green roofs, community gardens, and urban forests in new developments to enhance biodiversity and climate resilience.\n",
       "   - **Innovation**: Use permeable materials in urban design to manage stormwater sustainably, reducing flooding and improving water quality.\n",
       "\n",
       "4. **Local Food Production**:\n",
       "   - **Policy**: Create incentives for urban farming and community gardens, especially in food deserts.\n",
       "   - **Innovation**: Use hydroponic and vertical farming techniques to maximize space efficiency while providing fresh produce to local communities.\n",
       "\n",
       "5. **Renewable Energy Initiatives**:\n",
       "   - **Policy**: Offer tax credits and grants for residential and commercial solar installations and community renewable energy projects.\n",
       "   - **Innovation**: Develop community microgrids that empower neighborhoods to generate and manage their energy sustainably.\n",
       "\n",
       "6. **Sustainable Business Support**:\n",
       "   - **Policy**: Provide support for small and local businesses transitioning to green practices through funding and training.\n",
       "   - **Innovation**: Create innovation hubs or incubators that promote sustainable enterprises and technologies, fostering economic resilience.\n",
       "\n",
       "7. **Community Engagement Platforms**:\n",
       "   - **Policy**: Establish regular town hall meetings and stakeholder workshops to incorporate community input into planning and decision-making processes.\n",
       "   - **Innovation**: Use digital tools (e.g., online surveys, interactive mapping) to gather feedback from a wider audience, particularly marginalized communities.\n",
       "\n",
       "### Addressing Potential Opposition\n",
       "\n",
       "1. **Building Trust and Relationships**:\n",
       "   - Engage with community leaders, especially those from marginalized groups, to build trust and demonstrate a commitment to inclusive practices.\n",
       "   - Establish advisory boards that include diverse community representatives to guide policy decisions and innovations.\n",
       "\n",
       "2. **Transparent Communication**:\n",
       "   - Utilize clear, accessible language and materials to ensure that all residents understand the proposed changes and their benefits.\n",
       "   - Regularly update the community on progress and adapt plans based on feedback.\n",
       "\n",
       "3. **Addressing Economic Concerns**:\n",
       "   - Provide economic impact assessments to demonstrate how sustainable practices can benefit the local economy and create jobs.\n",
       "   - Offer job training and apprenticeship programs focusing on sustainable industries to ensure that existing residents benefit from new developments.\n",
       "\n",
       "4. **Compromise and Flexibility**:\n",
       "   - Be willing to modify proposals based on community feedback and concerns, ensuring that solutions are co-created with stakeholders.\n",
       "   - Host “design charrettes” where community members can visualize and contribute to solutions, thereby increasing their investment in the outcomes.\n",
       "\n",
       "5. **Highlighting Success Stories**:\n",
       "   - Showcase case studies from other urban areas that have successfully implemented similar sustainable and equitable initiatives to provide a blueprint for success and mitigate fears about change.\n",
       "\n",
       "6. **Monitoring and Evaluation**:\n",
       "   - Establish a framework for monitoring social equity and environmental sustainability metrics, ensuring accountability and transparency in the process.\n",
       "   - Use findings from assessments to continually refine and improve policies, addressing community concerns proactively.\n",
       "\n",
       "By taking a holistic and inclusive approach to urban redesign, it is possible to create a sustainable, equitable urban environment that meets the needs of all stakeholders, turning potential opposition into community support and collaboration."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Ethical Approaches to AI Deployment in Marginalized Communities\n",
       "\n",
       "I'd approach this complex challenge through several complementary frameworks:\n",
       "\n",
       "## Core Frameworks\n",
       "- **Participatory design**: Involve affected communities in AI development from inception through implementation\n",
       "- **Distributive justice**: Analyze how benefits and harms are distributed, prioritizing improvement for the most vulnerable\n",
       "- **Procedural justice**: Ensure transparency and meaningful opportunities for communities to contest decisions\n",
       "\n",
       "## Implementation Methods\n",
       "- Conduct rigorous bias audits before and after deployment using multiple fairness metrics\n",
       "- Implement oversight boards with substantial representation from affected communities\n",
       "- Establish clear accountability chains that don't end with algorithms but with responsible humans\n",
       "- Create accessible mechanisms for redress when systems cause harm\n",
       "\n",
       "## Specific Tools\n",
       "- Counterfactual fairness testing to detect disparate impacts\n",
       "- Algorithmic impact assessments with published results\n",
       "- Ongoing monitoring with regular public reporting on outcomes by demographic groups\n",
       "\n",
       "The most crucial principle is recognizing that technical solutions alone are insufficient without addressing underlying power dynamics and historical inequities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  20 KB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 170 KB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 225 KB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 375 KB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 578 KB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 949 KB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.2 MB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.2 MB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.5 MB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.5 MB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.5 MB/4.9 GB                  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.6 MB/4.9 GB  1.5 MB/s  53m22s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.7 MB/4.9 GB  1.5 MB/s  53m22s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 1.9 MB/4.9 GB  1.5 MB/s  53m22s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 2.0 MB/4.9 GB  1.5 MB/s  53m21s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 2.3 MB/4.9 GB  1.5 MB/s  53m21s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 2.9 MB/4.9 GB  1.5 MB/s  53m21s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 3.6 MB/4.9 GB  1.5 MB/s  53m20s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 5.2 MB/4.9 GB  1.5 MB/s  53m19s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 5.4 MB/4.9 GB  1.5 MB/s  53m19s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 5.5 MB/4.9 GB  1.5 MB/s  53m19s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 5.6 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 5.7 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.0 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.0 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.0 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.2 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.2 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.3 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 6.6 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 7.1 MB/4.9 GB  2.8 MB/s  29m34s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 7.7 MB/4.9 GB  2.5 MB/s  32m11s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 7.7 MB/4.9 GB  2.5 MB/s  32m11s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 8.0 MB/4.9 GB  2.5 MB/s  32m11s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 8.0 MB/4.9 GB  2.5 MB/s  32m11s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 8.2 MB/4.9 GB  2.5 MB/s  32m11s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 8.8 MB/4.9 GB  2.5 MB/s  32m11s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏ 9.2 MB/4.9 GB  2.5 MB/s  32m10s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  10 MB/4.9 GB  2.5 MB/s  32m10s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  11 MB/4.9 GB  2.5 MB/s  32m10s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  11 MB/4.9 GB  2.5 MB/s  32m10s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  11 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  11 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  11 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  12 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  12 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  12 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  12 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  13 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  13 MB/4.9 GB  2.9 MB/s  28m24s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  13 MB/4.9 GB  2.9 MB/s  28m23s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  14 MB/4.9 GB  2.8 MB/s  28m50s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  14 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  15 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  15 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  15 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  16 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  16 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  17 MB/4.9 GB  2.8 MB/s  28m49s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  17 MB/4.9 GB  2.8 MB/s  28m48s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  18 MB/4.9 GB  2.8 MB/s  28m48s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  18 MB/4.9 GB  2.8 MB/s  28m48s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  18 MB/4.9 GB  3.1 MB/s  26m26s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  19 MB/4.9 GB  3.1 MB/s  26m26s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  19 MB/4.9 GB  3.1 MB/s  26m26s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  19 MB/4.9 GB  3.1 MB/s  26m26s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  20 MB/4.9 GB  3.1 MB/s  26m26s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  20 MB/4.9 GB  3.1 MB/s  26m26s\u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 667b0c1932bc:   0% ▕                  ▏  20 MB/4.9 GB  3.1 MB/s  26m25s\u001b[K\u001b[?25h\u001b[?2026l^C\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Approaching the ethical dilemmas of deploying artificial intelligence (AI) in decision-making processes affecting marginalized communities requires a nuanced and multi-faceted approach. Here's a step-by-step framework for ensuring fairness and accountability:\n",
       "\n",
       "**1. Contextual understanding:**\n",
       "\n",
       "* Conduct thorough research on the social, economic, and cultural context of marginalized communities affected by AI-decisions.\n",
       "* Engage with experts from diverse backgrounds to ensure representation of various perspectives.\n",
       "\n",
       "**2. Establish clear goals and principles:**\n",
       "\n",
       "* Define a set of specific, measurable, achievable, relevant, and time-bound (SMART) objectives for AI deployment in decision-making processes.\n",
       "* Develop guiding principles that prioritize fairness, equity, transparency, accountability, and protect human rights and dignity.\n",
       "\n",
       "**3. Assess potential biases and risks:**\n",
       "\n",
       "* Systematically identify potential sources of bias in data, algorithms, and AI systems (e.g., data selection, sampling, representation).\n",
       "* Evaluate the likelihood and impact of adverse outcomes due to these biases.\n",
       "* Consider using tools like AI Explainability Protocols (AIEPs) or Data Auditing Frameworks.\n",
       "\n",
       "**4. Implement proactive mitigation strategies:**\n",
       "\n",
       "* Develop counter-narratives and interventions to mitigate potential biases and risks.\n",
       "* Integrate feedback mechanisms from diverse stakeholders, including marginalized communities, to rectify issues as they arise.\n",
       "* Use methods like iterative testing, public outreach, and transparent communication.\n",
       "\n",
       "**5. Prioritize inclusivity through co-design and participatory approaches:**\n",
       "\n",
       "* Engage critically with the social sciences, human-computer interaction (HCI), and computer ethics research to inform AI deployment strategies.\n",
       "* Incorporate marginalized perspectives in all aspects of AI development, from data curation to decision-making processes through co-design workshops.\n",
       "\n",
       "**Frameworks for fairness and accountability:**\n",
       "\n",
       "1. **Fairness Framework by Mitchell et al., 2018**: This framework evaluates the degree of fairness in AI decisions based on outcomes (e.g., accuracy, recall) across different subgroups.\n",
       "2. **Accountability Framework by Danks & Bennett, 2014**: This framework explores accountability through causal reasoning, focusing on attribution and responsibility for data quality and algorithmic biases.\n",
       "3. **UNICEF's Principles of Child-Friendly Artificial Intelligence:** These principles prioritize respect for children's rights, understanding cultural and social contexts, designing inclusive and accessible AI systems.\n",
       "\n",
       "**Key considerations:**\n",
       "\n",
       "* Ensure ongoing stakeholder engagement throughout the decision-making process to foster trust, inclusivity, and transparency.\n",
       "* Consider establishing external review mechanisms, such as advisory boards or ethics committees, composed of experts from diverse backgrounds.\n",
       "* Integrate an error reporting and accountability mechanism in the AI system itself.\n",
       "\n",
       "By integrating these frameworks into the design and deployment of artificial intelligence systems that affect marginalized communities, we can mitigate potential biases and uphold human rights principles."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.1\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claude-3-7-sonnet-latest', 'llama3.1']\n",
      "[\"# Ethical Approaches to AI Deployment in Marginalized Communities\\n\\nI'd approach this complex challenge through several complementary frameworks:\\n\\n## Core Frameworks\\n- **Participatory design**: Involve affected communities in AI development from inception through implementation\\n- **Distributive justice**: Analyze how benefits and harms are distributed, prioritizing improvement for the most vulnerable\\n- **Procedural justice**: Ensure transparency and meaningful opportunities for communities to contest decisions\\n\\n## Implementation Methods\\n- Conduct rigorous bias audits before and after deployment using multiple fairness metrics\\n- Implement oversight boards with substantial representation from affected communities\\n- Establish clear accountability chains that don't end with algorithms but with responsible humans\\n- Create accessible mechanisms for redress when systems cause harm\\n\\n## Specific Tools\\n- Counterfactual fairness testing to detect disparate impacts\\n- Algorithmic impact assessments with published results\\n- Ongoing monitoring with regular public reporting on outcomes by demographic groups\\n\\nThe most crucial principle is recognizing that technical solutions alone are insufficient without addressing underlying power dynamics and historical inequities.\", \"Approaching the ethical dilemmas of deploying artificial intelligence (AI) in decision-making processes affecting marginalized communities requires a nuanced and multi-faceted approach. Here's a step-by-step framework for ensuring fairness and accountability:\\n\\n**1. Contextual understanding:**\\n\\n* Conduct thorough research on the social, economic, and cultural context of marginalized communities affected by AI-decisions.\\n* Engage with experts from diverse backgrounds to ensure representation of various perspectives.\\n\\n**2. Establish clear goals and principles:**\\n\\n* Define a set of specific, measurable, achievable, relevant, and time-bound (SMART) objectives for AI deployment in decision-making processes.\\n* Develop guiding principles that prioritize fairness, equity, transparency, accountability, and protect human rights and dignity.\\n\\n**3. Assess potential biases and risks:**\\n\\n* Systematically identify potential sources of bias in data, algorithms, and AI systems (e.g., data selection, sampling, representation).\\n* Evaluate the likelihood and impact of adverse outcomes due to these biases.\\n* Consider using tools like AI Explainability Protocols (AIEPs) or Data Auditing Frameworks.\\n\\n**4. Implement proactive mitigation strategies:**\\n\\n* Develop counter-narratives and interventions to mitigate potential biases and risks.\\n* Integrate feedback mechanisms from diverse stakeholders, including marginalized communities, to rectify issues as they arise.\\n* Use methods like iterative testing, public outreach, and transparent communication.\\n\\n**5. Prioritize inclusivity through co-design and participatory approaches:**\\n\\n* Engage critically with the social sciences, human-computer interaction (HCI), and computer ethics research to inform AI deployment strategies.\\n* Incorporate marginalized perspectives in all aspects of AI development, from data curation to decision-making processes through co-design workshops.\\n\\n**Frameworks for fairness and accountability:**\\n\\n1. **Fairness Framework by Mitchell et al., 2018**: This framework evaluates the degree of fairness in AI decisions based on outcomes (e.g., accuracy, recall) across different subgroups.\\n2. **Accountability Framework by Danks & Bennett, 2014**: This framework explores accountability through causal reasoning, focusing on attribution and responsibility for data quality and algorithmic biases.\\n3. **UNICEF's Principles of Child-Friendly Artificial Intelligence:** These principles prioritize respect for children's rights, understanding cultural and social contexts, designing inclusive and accessible AI systems.\\n\\n**Key considerations:**\\n\\n* Ensure ongoing stakeholder engagement throughout the decision-making process to foster trust, inclusivity, and transparency.\\n* Consider establishing external review mechanisms, such as advisory boards or ethics committees, composed of experts from diverse backgrounds.\\n* Integrate an error reporting and accountability mechanism in the AI system itself.\\n\\nBy integrating these frameworks into the design and deployment of artificial intelligence systems that affect marginalized communities, we can mitigate potential biases and uphold human rights principles.\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: claude-3-7-sonnet-latest\n",
      "\n",
      "# Ethical Approaches to AI Deployment in Marginalized Communities\n",
      "\n",
      "I'd approach this complex challenge through several complementary frameworks:\n",
      "\n",
      "## Core Frameworks\n",
      "- **Participatory design**: Involve affected communities in AI development from inception through implementation\n",
      "- **Distributive justice**: Analyze how benefits and harms are distributed, prioritizing improvement for the most vulnerable\n",
      "- **Procedural justice**: Ensure transparency and meaningful opportunities for communities to contest decisions\n",
      "\n",
      "## Implementation Methods\n",
      "- Conduct rigorous bias audits before and after deployment using multiple fairness metrics\n",
      "- Implement oversight boards with substantial representation from affected communities\n",
      "- Establish clear accountability chains that don't end with algorithms but with responsible humans\n",
      "- Create accessible mechanisms for redress when systems cause harm\n",
      "\n",
      "## Specific Tools\n",
      "- Counterfactual fairness testing to detect disparate impacts\n",
      "- Algorithmic impact assessments with published results\n",
      "- Ongoing monitoring with regular public reporting on outcomes by demographic groups\n",
      "\n",
      "The most crucial principle is recognizing that technical solutions alone are insufficient without addressing underlying power dynamics and historical inequities.\n",
      "Competitor: llama3.1\n",
      "\n",
      "Approaching the ethical dilemmas of deploying artificial intelligence (AI) in decision-making processes affecting marginalized communities requires a nuanced and multi-faceted approach. Here's a step-by-step framework for ensuring fairness and accountability:\n",
      "\n",
      "**1. Contextual understanding:**\n",
      "\n",
      "* Conduct thorough research on the social, economic, and cultural context of marginalized communities affected by AI-decisions.\n",
      "* Engage with experts from diverse backgrounds to ensure representation of various perspectives.\n",
      "\n",
      "**2. Establish clear goals and principles:**\n",
      "\n",
      "* Define a set of specific, measurable, achievable, relevant, and time-bound (SMART) objectives for AI deployment in decision-making processes.\n",
      "* Develop guiding principles that prioritize fairness, equity, transparency, accountability, and protect human rights and dignity.\n",
      "\n",
      "**3. Assess potential biases and risks:**\n",
      "\n",
      "* Systematically identify potential sources of bias in data, algorithms, and AI systems (e.g., data selection, sampling, representation).\n",
      "* Evaluate the likelihood and impact of adverse outcomes due to these biases.\n",
      "* Consider using tools like AI Explainability Protocols (AIEPs) or Data Auditing Frameworks.\n",
      "\n",
      "**4. Implement proactive mitigation strategies:**\n",
      "\n",
      "* Develop counter-narratives and interventions to mitigate potential biases and risks.\n",
      "* Integrate feedback mechanisms from diverse stakeholders, including marginalized communities, to rectify issues as they arise.\n",
      "* Use methods like iterative testing, public outreach, and transparent communication.\n",
      "\n",
      "**5. Prioritize inclusivity through co-design and participatory approaches:**\n",
      "\n",
      "* Engage critically with the social sciences, human-computer interaction (HCI), and computer ethics research to inform AI deployment strategies.\n",
      "* Incorporate marginalized perspectives in all aspects of AI development, from data curation to decision-making processes through co-design workshops.\n",
      "\n",
      "**Frameworks for fairness and accountability:**\n",
      "\n",
      "1. **Fairness Framework by Mitchell et al., 2018**: This framework evaluates the degree of fairness in AI decisions based on outcomes (e.g., accuracy, recall) across different subgroups.\n",
      "2. **Accountability Framework by Danks & Bennett, 2014**: This framework explores accountability through causal reasoning, focusing on attribution and responsibility for data quality and algorithmic biases.\n",
      "3. **UNICEF's Principles of Child-Friendly Artificial Intelligence:** These principles prioritize respect for children's rights, understanding cultural and social contexts, designing inclusive and accessible AI systems.\n",
      "\n",
      "**Key considerations:**\n",
      "\n",
      "* Ensure ongoing stakeholder engagement throughout the decision-making process to foster trust, inclusivity, and transparency.\n",
      "* Consider establishing external review mechanisms, such as advisory boards or ethics committees, composed of experts from diverse backgrounds.\n",
      "* Integrate an error reporting and accountability mechanism in the AI system itself.\n",
      "\n",
      "By integrating these frameworks into the design and deployment of artificial intelligence systems that affect marginalized communities, we can mitigate potential biases and uphold human rights principles.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "# Ethical Approaches to AI Deployment in Marginalized Communities\n",
      "\n",
      "I'd approach this complex challenge through several complementary frameworks:\n",
      "\n",
      "## Core Frameworks\n",
      "- **Participatory design**: Involve affected communities in AI development from inception through implementation\n",
      "- **Distributive justice**: Analyze how benefits and harms are distributed, prioritizing improvement for the most vulnerable\n",
      "- **Procedural justice**: Ensure transparency and meaningful opportunities for communities to contest decisions\n",
      "\n",
      "## Implementation Methods\n",
      "- Conduct rigorous bias audits before and after deployment using multiple fairness metrics\n",
      "- Implement oversight boards with substantial representation from affected communities\n",
      "- Establish clear accountability chains that don't end with algorithms but with responsible humans\n",
      "- Create accessible mechanisms for redress when systems cause harm\n",
      "\n",
      "## Specific Tools\n",
      "- Counterfactual fairness testing to detect disparate impacts\n",
      "- Algorithmic impact assessments with published results\n",
      "- Ongoing monitoring with regular public reporting on outcomes by demographic groups\n",
      "\n",
      "The most crucial principle is recognizing that technical solutions alone are insufficient without addressing underlying power dynamics and historical inequities.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Approaching the ethical dilemmas of deploying artificial intelligence (AI) in decision-making processes affecting marginalized communities requires a nuanced and multi-faceted approach. Here's a step-by-step framework for ensuring fairness and accountability:\n",
      "\n",
      "**1. Contextual understanding:**\n",
      "\n",
      "* Conduct thorough research on the social, economic, and cultural context of marginalized communities affected by AI-decisions.\n",
      "* Engage with experts from diverse backgrounds to ensure representation of various perspectives.\n",
      "\n",
      "**2. Establish clear goals and principles:**\n",
      "\n",
      "* Define a set of specific, measurable, achievable, relevant, and time-bound (SMART) objectives for AI deployment in decision-making processes.\n",
      "* Develop guiding principles that prioritize fairness, equity, transparency, accountability, and protect human rights and dignity.\n",
      "\n",
      "**3. Assess potential biases and risks:**\n",
      "\n",
      "* Systematically identify potential sources of bias in data, algorithms, and AI systems (e.g., data selection, sampling, representation).\n",
      "* Evaluate the likelihood and impact of adverse outcomes due to these biases.\n",
      "* Consider using tools like AI Explainability Protocols (AIEPs) or Data Auditing Frameworks.\n",
      "\n",
      "**4. Implement proactive mitigation strategies:**\n",
      "\n",
      "* Develop counter-narratives and interventions to mitigate potential biases and risks.\n",
      "* Integrate feedback mechanisms from diverse stakeholders, including marginalized communities, to rectify issues as they arise.\n",
      "* Use methods like iterative testing, public outreach, and transparent communication.\n",
      "\n",
      "**5. Prioritize inclusivity through co-design and participatory approaches:**\n",
      "\n",
      "* Engage critically with the social sciences, human-computer interaction (HCI), and computer ethics research to inform AI deployment strategies.\n",
      "* Incorporate marginalized perspectives in all aspects of AI development, from data curation to decision-making processes through co-design workshops.\n",
      "\n",
      "**Frameworks for fairness and accountability:**\n",
      "\n",
      "1. **Fairness Framework by Mitchell et al., 2018**: This framework evaluates the degree of fairness in AI decisions based on outcomes (e.g., accuracy, recall) across different subgroups.\n",
      "2. **Accountability Framework by Danks & Bennett, 2014**: This framework explores accountability through causal reasoning, focusing on attribution and responsibility for data quality and algorithmic biases.\n",
      "3. **UNICEF's Principles of Child-Friendly Artificial Intelligence:** These principles prioritize respect for children's rights, understanding cultural and social contexts, designing inclusive and accessible AI systems.\n",
      "\n",
      "**Key considerations:**\n",
      "\n",
      "* Ensure ongoing stakeholder engagement throughout the decision-making process to foster trust, inclusivity, and transparency.\n",
      "* Consider establishing external review mechanisms, such as advisory boards or ethics committees, composed of experts from diverse backgrounds.\n",
      "* Integrate an error reporting and accountability mechanism in the AI system itself.\n",
      "\n",
      "By integrating these frameworks into the design and deployment of artificial intelligence systems that affect marginalized communities, we can mitigate potential biases and uphold human rights principles.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you approach the ethical dilemmas presented by the deployment of artificial intelligence in decision-making processes that affect marginalized communities, and what specific frameworks would you utilize to ensure fairness and accountability?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "# Ethical Approaches to AI Deployment in Marginalized Communities\n",
      "\n",
      "I'd approach this complex challenge through several complementary frameworks:\n",
      "\n",
      "## Core Frameworks\n",
      "- **Participatory design**: Involve affected communities in AI development from inception through implementation\n",
      "- **Distributive justice**: Analyze how benefits and harms are distributed, prioritizing improvement for the most vulnerable\n",
      "- **Procedural justice**: Ensure transparency and meaningful opportunities for communities to contest decisions\n",
      "\n",
      "## Implementation Methods\n",
      "- Conduct rigorous bias audits before and after deployment using multiple fairness metrics\n",
      "- Implement oversight boards with substantial representation from affected communities\n",
      "- Establish clear accountability chains that don't end with algorithms but with responsible humans\n",
      "- Create accessible mechanisms for redress when systems cause harm\n",
      "\n",
      "## Specific Tools\n",
      "- Counterfactual fairness testing to detect disparate impacts\n",
      "- Algorithmic impact assessments with published results\n",
      "- Ongoing monitoring with regular public reporting on outcomes by demographic groups\n",
      "\n",
      "The most crucial principle is recognizing that technical solutions alone are insufficient without addressing underlying power dynamics and historical inequities.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Approaching the ethical dilemmas of deploying artificial intelligence (AI) in decision-making processes affecting marginalized communities requires a nuanced and multi-faceted approach. Here's a step-by-step framework for ensuring fairness and accountability:\n",
      "\n",
      "**1. Contextual understanding:**\n",
      "\n",
      "* Conduct thorough research on the social, economic, and cultural context of marginalized communities affected by AI-decisions.\n",
      "* Engage with experts from diverse backgrounds to ensure representation of various perspectives.\n",
      "\n",
      "**2. Establish clear goals and principles:**\n",
      "\n",
      "* Define a set of specific, measurable, achievable, relevant, and time-bound (SMART) objectives for AI deployment in decision-making processes.\n",
      "* Develop guiding principles that prioritize fairness, equity, transparency, accountability, and protect human rights and dignity.\n",
      "\n",
      "**3. Assess potential biases and risks:**\n",
      "\n",
      "* Systematically identify potential sources of bias in data, algorithms, and AI systems (e.g., data selection, sampling, representation).\n",
      "* Evaluate the likelihood and impact of adverse outcomes due to these biases.\n",
      "* Consider using tools like AI Explainability Protocols (AIEPs) or Data Auditing Frameworks.\n",
      "\n",
      "**4. Implement proactive mitigation strategies:**\n",
      "\n",
      "* Develop counter-narratives and interventions to mitigate potential biases and risks.\n",
      "* Integrate feedback mechanisms from diverse stakeholders, including marginalized communities, to rectify issues as they arise.\n",
      "* Use methods like iterative testing, public outreach, and transparent communication.\n",
      "\n",
      "**5. Prioritize inclusivity through co-design and participatory approaches:**\n",
      "\n",
      "* Engage critically with the social sciences, human-computer interaction (HCI), and computer ethics research to inform AI deployment strategies.\n",
      "* Incorporate marginalized perspectives in all aspects of AI development, from data curation to decision-making processes through co-design workshops.\n",
      "\n",
      "**Frameworks for fairness and accountability:**\n",
      "\n",
      "1. **Fairness Framework by Mitchell et al., 2018**: This framework evaluates the degree of fairness in AI decisions based on outcomes (e.g., accuracy, recall) across different subgroups.\n",
      "2. **Accountability Framework by Danks & Bennett, 2014**: This framework explores accountability through causal reasoning, focusing on attribution and responsibility for data quality and algorithmic biases.\n",
      "3. **UNICEF's Principles of Child-Friendly Artificial Intelligence:** These principles prioritize respect for children's rights, understanding cultural and social contexts, designing inclusive and accessible AI systems.\n",
      "\n",
      "**Key considerations:**\n",
      "\n",
      "* Ensure ongoing stakeholder engagement throughout the decision-making process to foster trust, inclusivity, and transparency.\n",
      "* Consider establishing external review mechanisms, such as advisory boards or ethics committees, composed of experts from diverse backgrounds.\n",
      "* Integrate an error reporting and accountability mechanism in the AI system itself.\n",
      "\n",
      "By integrating these frameworks into the design and deployment of artificial intelligence systems that affect marginalized communities, we can mitigate potential biases and uphold human rights principles.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: llama3.1\n",
      "Rank 2: claude-3-7-sonnet-latest\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "judge model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            and common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
